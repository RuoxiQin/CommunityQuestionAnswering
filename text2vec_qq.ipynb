{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for the Question Retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_length = 100\n",
    "vector_size = 300\n",
    "train_path = 'v3.2/train/'\n",
    "train_fileName1 = 'SemEval2016-Task3-CQA-QL-train-part1.xml'\n",
    "train_fileName2 = 'SemEval2016-Task3-CQA-QL-train-part2.xml'\n",
    "test_path = 'v3.2/test/'\n",
    "test_fileName = 'SemEval2016-Task3-CQA-QL-test.xml'\n",
    "word2vec_matrix = 'GoogleNews-vectors-negative300.bin'\n",
    "cQQ_train_embedding_name = 'cQQ_train_embedding'\n",
    "cQQ_test_embedding_name = 'cQQ_test_embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RawDataExtractor:\n",
    "    def __init__(self, path, fileName):\n",
    "        self.tree = ET.parse(path + fileName)\n",
    "        self.root = self.tree.getroot()\n",
    "    \n",
    "    # Use this function to load QA related data ONLY!\n",
    "    def extractInformation_QA(self, test = False, testSize = 5):\n",
    "        '''\n",
    "        This function returns a python dictionary which has the following structure:\n",
    "        infoDic = {\n",
    "            'Q1_R1': {\n",
    "                'qTime': string\n",
    "                'qTime_UNIX': float\n",
    "                'qSubject': string\n",
    "                'qUserID': string\n",
    "                'qUserID_INT': int\n",
    "                'qBody': string\n",
    "                'comments': {\n",
    "                    'cID': {\n",
    "                        'cTime': string\n",
    "                        'cTime_UNIX': float\n",
    "                        'cUserID': string\n",
    "                        'cUserID_INT': int\n",
    "                        'cBody': string\n",
    "                        'cLabel': string  \n",
    "                        'cLabel_INT': int\n",
    "                    }  \n",
    "                    ...\n",
    "                }\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "        '''\n",
    "        infoDic = {}\n",
    "        # For testing ONLY:\n",
    "        count = 0\n",
    "        for child in self.root:\n",
    "            # For testing ONLY:\n",
    "            if test:\n",
    "                count += 1\n",
    "                if count > testSize:\n",
    "                    return infoDic\n",
    "            # Get the question key\n",
    "            currentQuestionKey = child.attrib.get('THREAD_SEQUENCE')\n",
    "            # Get the question dictionary\n",
    "            currentQuestion = self.extractSingleInformation_QA(child)\n",
    "            if not infoDic.get(currentQuestionKey):\n",
    "                infoDic[currentQuestionKey] = currentQuestion\n",
    "            else:\n",
    "                print('%s key has already existed. Info extraction failed...')\n",
    "                return None\n",
    "        return infoDic\n",
    "    \n",
    "    def extractSingleInformation_QA(self, child):\n",
    "        singleInfoDic = {}\n",
    "        singleInfoDic['comments'] = {}\n",
    "        for index in range(len(child)):    \n",
    "            # Question\n",
    "            element = child[index]\n",
    "            if index == 0 and element.attrib.get('RELQ_ID'):\n",
    "                # Question Time\n",
    "                qt = element.attrib.get('RELQ_DATE')\n",
    "                singleInfoDic['qTime'] = qt\n",
    "                dt = datetime.datetime.strptime(qt, '%Y-%m-%d %H:%M:%S')\n",
    "                singleInfoDic['qTime_UNIX'] = dt.timestamp()\n",
    "                # Question User ID, both string and int format\n",
    "#                 singleInfoDic['qID'] = element.attrib.get('RELQ_ID')\n",
    "                singleInfoDic['qUserID'] = element.attrib.get('RELQ_USERID')\n",
    "                qUserID_int = int(singleInfoDic['qUserID'].replace('U', ''))\n",
    "                singleInfoDic['qUserID_INT'] = qUserID_int\n",
    "                # Question Subject\n",
    "                singleInfoDic['qSubject'] = element[0].text\n",
    "                # Question Body\n",
    "                singleInfoDic['qBody'] = element[1].text   \n",
    "            else:\n",
    "                commentKey = element.attrib.get('RELC_ID') #cID\n",
    "                singleInfoDic['comments'][commentKey] = {}\n",
    "                # Comment Time\n",
    "                ct = element.attrib.get('RELC_DATE')\n",
    "                singleInfoDic['comments'][commentKey]['cTime'] = ct\n",
    "                dt = datetime.datetime.strptime(ct, '%Y-%m-%d %H:%M:%S')\n",
    "                singleInfoDic['comments'][commentKey]['cTime_UNIX'] = dt.timestamp()\n",
    "                # Comment ID\n",
    "                singleInfoDic['comments'][commentKey]['cUserID'] = element.attrib.get('RELC_USERID')\n",
    "                cUserID_int = int(singleInfoDic['comments'][commentKey]['cUserID'].replace('U', ''))\n",
    "                singleInfoDic['comments'][commentKey]['cUserID_INT'] = cUserID_int\n",
    "                # Comment Body\n",
    "                singleInfoDic['comments'][commentKey]['cBody'] = element[0].text\n",
    "                # Comment Label\n",
    "                label = element.attrib.get('RELC_RELEVANCE2RELQ')\n",
    "                singleInfoDic['comments'][commentKey]['cLabel'] = label\n",
    "                if label == 'Good':\n",
    "                    singleInfoDic['comments'][commentKey]['cLabel_INT'] = 2\n",
    "                elif label == 'Bad':\n",
    "                    singleInfoDic['comments'][commentKey]['cLabel_INT'] = 0\n",
    "                else:\n",
    "                    singleInfoDic['comments'][commentKey]['cLabel_INT'] = 1\n",
    "        return singleInfoDic\n",
    "\n",
    "    # Use this function to load QQ related data ONLY!\n",
    "    def extractInformation_QQ(self, test = False, testSize = 30):\n",
    "        '''\n",
    "        This function returns a python dictionary which has the following structure:\n",
    "        infoDic = {\n",
    "            'Q1': {\n",
    "                'qTargetSubject': string\n",
    "                'qTargetBody': string\n",
    "                'availableQs': {\n",
    "                    availableQID :{\n",
    "                        'qTime': string\n",
    "                        'qTime_UNIX': float\n",
    "                        'qSubject': string\n",
    "                        'qUserID': string\n",
    "                        'qUserID_INT': int\n",
    "                        'qBody': string\n",
    "                        'qLabel': string\n",
    "                        'qLabel_INT': int\n",
    "                        'qRankingOrder': int\n",
    "                        'qCategory': string\n",
    "                    }\n",
    "                    ...  \n",
    "                }\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "        '''\n",
    "        infoDic = {}\n",
    "        \n",
    "        # For testing ONLY:\n",
    "        count = 0\n",
    "        questionKeyRecorder = None\n",
    "        \n",
    "        for child in self.root:\n",
    "            # For testing ONLY:\n",
    "            if test:\n",
    "                count += 1\n",
    "                if count > testSize:\n",
    "                    return infoDic\n",
    "            # Get the question key\n",
    "            currentQuestionKey = child.attrib.get('ORGQ_ID')\n",
    "            # Get the question dictionary\n",
    "            \n",
    "            # A new target question\n",
    "            if questionKeyRecorder == None or questionKeyRecorder != currentQuestionKey:\n",
    "                questionKeyRecorder = currentQuestionKey\n",
    "                infoDic[currentQuestionKey] = {}\n",
    "                infoDic[currentQuestionKey]['qTargetSubject'] = child[0].text\n",
    "                infoDic[currentQuestionKey]['qTargetBody'] = child[1].text\n",
    "                infoDic[currentQuestionKey]['availableQs'] = {}\n",
    "                \n",
    "            # Handling the question\n",
    "            availQKey = child[2].attrib.get('THREAD_SEQUENCE')\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey] = {}\n",
    "            # Time        \n",
    "            ct = child[2][0].attrib.get('RELQ_DATE')\n",
    "            dt = datetime.datetime.strptime(ct, '%Y-%m-%d %H:%M:%S')\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qTime'] = ct\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qTime_UNIX'] = dt.timestamp()\n",
    "            # User ID\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qUserID'] = child[2][0].attrib.get('RELQ_USERID')\n",
    "            qUserID_int = int(child[2][0].attrib.get('RELQ_USERID').replace('U', ''))\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qUserID_INT'] = qUserID_int\n",
    "            \n",
    "            # Subject and Body\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qSubject'] = child[2][0][0].text\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qBody'] = child[2][0][1].text\n",
    "            \n",
    "            # Label\n",
    "            currentLabel = child[2][0].attrib.get('RELQ_RELEVANCE2ORGQ')\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qLabel'] = currentLabel\n",
    "            \n",
    "            if currentLabel == 'PerfectMatch':\n",
    "                infoDic[currentQuestionKey]['availableQs'][availQKey]['qLabel_INT'] = 2\n",
    "            elif currentLabel == 'Irrelevant':\n",
    "                infoDic[currentQuestionKey]['availableQs'][availQKey]['qLabel_INT'] = 0\n",
    "            else:\n",
    "                infoDic[currentQuestionKey]['availableQs'][availQKey]['qLabel_INT'] = 1\n",
    "            \n",
    "            # Other information\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qRankingOrder'] = int(child[2][0].attrib.get('RELQ_RANKING_ORDER'))\n",
    "            infoDic[currentQuestionKey]['availableQs'][availQKey]['qCategory'] = child[2][0].attrib.get('RELQ_CATEGORY')\n",
    "            \n",
    "        return infoDic \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Text2Vec:\n",
    "    def __init__(self, word2vec_model, vector_dim, sentence_length):\n",
    "        self.model = word2vec_model\n",
    "        self.vector_dim = vector_dim\n",
    "        self.sentence_length = sentence_length\n",
    "        self.pattern = re.compile(r\"[^\\w]\")\n",
    "        replace_op = lambda x: self.pattern.sub('', x)\n",
    "        self.ops = [lambda x: x, lambda x: x.lower(), lambda x: x.capitalize(), lambda x: x.upper(), \\\n",
    "                   lambda x: replace_op(x), lambda x: replace_op(x).lower(), \\\n",
    "                    lambda x: replace_op(x).capitalize(), lambda x: replace_op(x).upper()]\n",
    "        \n",
    "    def embed_sentence(self, sentence):\n",
    "        words = sentence.strip().split()\n",
    "        vectors = []\n",
    "        for w in words[:self.sentence_length]:\n",
    "            for op in self.ops:\n",
    "                new_w = op(w)\n",
    "                if new_w in self.model.vocab:\n",
    "                    vectors.append(self.model[new_w].reshape((1, -1)))\n",
    "                    break\n",
    "            else:\n",
    "                vectors.append(np.random.uniform(low=-0.25, high=0.25, size=(1, self.vector_dim)))\n",
    "        if len(vectors) < self.sentence_length:\n",
    "            vectors.append(np.zeros((self.sentence_length - len(vectors), self.vector_dim)))\n",
    "        return np.concatenate(vectors, axis=0).reshape(1, self.sentence_length, self.vector_dim)\n",
    "    \n",
    "    def build_matrix(self, raw_dict, save_dir):\n",
    "        q_vectors = []\n",
    "        a_vectors = []\n",
    "        labels = []\n",
    "        aug_data = []\n",
    "        cid_list = []\n",
    "        for thread in raw_dict.values():\n",
    "            q_vector = self.embed_sentence((thread['qTargetSubject'] if thread['qTargetSubject'] else '') + \\\n",
    "                                           ' ' + thread['qTargetBody'] if thread['qTargetBody'] else '')\n",
    "            tmp_time = []\n",
    "            if len(thread['availableQs']) != 10:\n",
    "                print('Invalid thread length: ', len(thread['availableQs']))\n",
    "                continue\n",
    "            for cid, comment in thread['availableQs'].items():\n",
    "                q_vectors.append(q_vector)\n",
    "                a_vectors.append(self.embed_sentence((comment['qSubject'] if comment['qSubject'] else '') + \\\n",
    "                                           ' ' + comment['qBody'] if comment['qBody'] else ''))\n",
    "                labels.append(np.array([[comment['qLabel_INT'] / 2]]))\n",
    "                cid_list.append(np.array([[cid]]))\n",
    "                tmp_time.append(comment['qRankingOrder'])\n",
    "            for order in np.argsort(tmp_time):\n",
    "                aug = np.zeros((1, 10))\n",
    "                aug[0, order] = 1.0\n",
    "                aug_data.append(aug)\n",
    "        q_vec = np.concatenate(q_vectors, axis=0)\n",
    "        a_vec = np.concatenate(a_vectors, axis=0)\n",
    "        label_vec = np.concatenate(labels, axis=0)\n",
    "        aug_vec = np.concatenate(aug_data, axis=0)\n",
    "        cid_vec = np.concatenate(cid_list, axis=0)\n",
    "        np.savez(save_dir, q_vec, a_vec, aug_vec, label_vec, cid_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(word2vec_matrix, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2v = Text2Vec(w2v_model, vector_size, sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid thread length:  9\n"
     ]
    }
   ],
   "source": [
    "rDE1 = RawDataExtractor(train_path, train_fileName1)\n",
    "raw_dict1 = rDE1.extractInformation_QQ(test = False, testSize = 50)\n",
    "rDE2 = RawDataExtractor(train_path, train_fileName2)\n",
    "raw_dict2 = rDE2.extractInformation_QQ(test = False, testSize = 50)\n",
    "raw_dict = {**raw_dict1, **raw_dict2}\n",
    "t2v.build_matrix(raw_dict, cQQ_train_embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rDE = RawDataExtractor(test_path, test_fileName)\n",
    "raw_dict = rDE.extractInformation_QQ(test = False, testSize = 50)\n",
    "t2v.build_matrix(raw_dict, cQQ_test_embedding_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may print your generated embedding vectors using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npz_data = np.load(cQQ_train_embedding_name + '.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_data['arr_2'][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
