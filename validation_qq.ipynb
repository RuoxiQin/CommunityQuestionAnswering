{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_length = 100\n",
    "vector_size = 300\n",
    "batch_size = 16\n",
    "hidden_units1 = 64\n",
    "hidden_units2 = 32\n",
    "learning_rate = 0.001\n",
    "drop_rate = 0.5\n",
    "augment_feature_num = 10\n",
    "dense_units1 = 20\n",
    "dense_units2 = 10\n",
    "reg_coefficient = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, data_dir):\n",
    "        '''Initialization'''\n",
    "        npz_data = np.load(data_dir)\n",
    "        names = sorted(npz_data.files)\n",
    "        self._data = []\n",
    "        for name in names:\n",
    "            self._data.append(npz_data[name])\n",
    "        self._num_examples = self._data[0].shape[0]\n",
    "\n",
    "    def shuffle_data(self, idx):\n",
    "        for i in range(len(self._data)):\n",
    "            self._data[i]=self._data[i][idx]\n",
    "\n",
    "    def get_data(self, start, end):\n",
    "        res=[]\n",
    "        for i in range(len(self._data)):\n",
    "            res.append(self._data[i][start : end])\n",
    "        return res\n",
    "    \n",
    "    def init_epoch(self, batch_size, shuffle=True):\n",
    "        self._index_in_epoch = 0\n",
    "        idx = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idx)  # shuffle indexes\n",
    "        self.shuffle_data(idx)  # get list of `num` random samples\n",
    "        if batch_size <= 0:\n",
    "            self.batch_size = self._num_examples\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "    def has_next(self):\n",
    "        '''return bool: whether there is a next batch'''\n",
    "        return self._index_in_epoch < self._num_examples\n",
    "\n",
    "    def get_batch(self):\n",
    "        '''\n",
    "        return the next batch in the following tuple format:\n",
    "        (batch_input_q, batch_input_a, augmented_data, score_label)\n",
    "        Where\n",
    "        batch_input_q: word2vec representation for the question in shape [batch_size, sentence_length, vector_size]\n",
    "        batch_input_a: word2vec representation for the answer in shape [batch_size, sentence_length, vector_size]\n",
    "        augmented_data: the extra data for MLP in shape [batch_size, augment_feature_num]\n",
    "        score_label: ground truth semantic similarity score in shape [batch_size, 1]\n",
    "        '''\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += self.batch_size\n",
    "        end = self._index_in_epoch\n",
    "        return self.get_data(start, end)\n",
    "\n",
    "#-----------------------Model definition--------------------------------\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# placeholders\n",
    "batch_input_q = tf.placeholder(dtype=tf.float32, shape=(None, sentence_length, vector_size))\n",
    "batch_input_a = tf.placeholder(dtype=tf.float32, shape=(None, sentence_length, vector_size))\n",
    "augmented_data = tf.placeholder(dtype=tf.float32, shape=(None, augment_feature_num))\n",
    "score_label = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "enable_dropout = tf.placeholder(dtype=tf.bool, shape=())\n",
    "batch_input = tf.concat(values=[batch_input_q, batch_input_a], axis=1)\n",
    "# bidirectional lstms\n",
    "cell_fw1 = tf.nn.rnn_cell.LSTMCell(num_units=hidden_units1, name='forward1')\n",
    "cell_bw1 = tf.nn.rnn_cell.LSTMCell(num_units=hidden_units1, name='backward1')\n",
    "outputs1, states1 = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw=cell_fw1, cell_bw=cell_bw1, inputs=batch_input, dtype=tf.float32)\n",
    "batch_middle = tf.concat(values=outputs1, axis=2)\n",
    "cell_fw2 = tf.nn.rnn_cell.LSTMCell(num_units=hidden_units2, name='forward2')\n",
    "cell_bw2 = tf.nn.rnn_cell.LSTMCell(num_units=hidden_units2, name='backward2')\n",
    "outputs2, states2 = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw=cell_fw2, cell_bw=cell_bw2, inputs=batch_middle, dtype=tf.float32)\n",
    "output_fw2, output_bw2 = outputs2\n",
    "bilstm_output = output_fw2 + output_bw2\n",
    "bilstm_flaten = tf.reshape(bilstm_output, (-1, hidden_units2 * sentence_length * 2))\n",
    "\n",
    "dense0 = tf.layers.dense(bilstm_flaten, augment_feature_num, activation=tf.nn.relu, name='dense0')\n",
    "mlp_batch_input = tf.concat(values=[dense0, augmented_data], axis=1)\n",
    "# multi-layers perceptrons\n",
    "dropout1 = tf.layers.dropout(mlp_batch_input, rate=drop_rate, training=enable_dropout, name='dropout1')\n",
    "dense1 = tf.layers.dense(dropout1, dense_units1, activation=tf.nn.relu, name='dense1')\n",
    "dropout2 = tf.layers.dropout(dense1, rate=drop_rate, training=enable_dropout, name='dropout2')\n",
    "dense2 = tf.layers.dense(dropout2, dense_units2, activation=tf.nn.relu, name='dense2')\n",
    "dropout3 = tf.layers.dropout(dense2, rate=drop_rate, training=enable_dropout, name='dropout3')\n",
    "logits = tf.layers.dense(dropout3, 1, name='final_output')\n",
    "batch_loss = tf.losses.mean_squared_error(score_label, logits)\n",
    "tf.summary.scalar('batch_mse_loss', batch_loss)\n",
    "# regularization term\n",
    "tv = tf.trainable_variables()\n",
    "regularization = tf.reduce_sum([tf.nn.l2_loss(v) for v in tv])\n",
    "tf.summary.scalar('regularization', regularization)\n",
    "loss_with_reg = batch_loss + reg_coefficient * regularization\n",
    "tf.summary.scalar('loss_with_regularization', loss_with_reg)\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_with_reg, name='train_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(matrices, log_dir):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, log_dir + \"/model.ckpt\")\n",
    "        input_q, input_a, aug_data = matrices\n",
    "        scores = sess.run(logits, feed_dict={\n",
    "                batch_input_q: input_q,\n",
    "                batch_input_a: input_a,\n",
    "                augmented_data: aug_data,\n",
    "                enable_dropout: False})\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_driver(data_generator, log_dir, thread_len=10):\n",
    "    data_generator.init_epoch(-1, shuffle=False)\n",
    "    q_vec, a_vec, aug_data, label_vec, cid_list = data_generator.get_batch()\n",
    "    pred_vec = predict_score([q_vec, a_vec, aug_data], log_dir)\n",
    "    ans = []\n",
    "    ans_human = []\n",
    "    print(label_vec.shape, pred_vec.shape)\n",
    "    for i in range(0, q_vec.shape[0], thread_len):\n",
    "        tmp_rank = []\n",
    "        tmp_rank_human = []\n",
    "        for j in range(thread_len):\n",
    "            tmp_rank.append((float(pred_vec[i + j]), j, round(2 * float(label_vec[i + j]))))\n",
    "            tmp_rank_human.append((float(pred_vec[i + j]), j, round(2 * float(label_vec[i + j])), str(cid_list[i + j][0])))\n",
    "        tmp_rank.sort(reverse=True)\n",
    "        tmp_rank_human.sort(reverse=True)\n",
    "        ans.append(tmp_rank)\n",
    "        ans_human.append(tmp_rank_human)\n",
    "    return ans, ans_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = 'result_qq_' + str(hidden_units1) + '_' + str(hidden_units2) + '_' +\\\n",
    "str(dense_units1) + '_' + str(dense_units2) + '_' + str(reg_coefficient)\n",
    "log_dir = root_dir + '/log'\n",
    "tensorboard_dir = root_dir + '/tensorboard'\n",
    "cQQ_test_embedding_dir = 'cQQ_test_embedding.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from result_qq_att_64_32_20_10_0.0001/log/model.ckpt\n",
      "(700, 1) (700, 1)\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "test_data_generator = DataGenerator(cQQ_test_embedding_dir)\n",
    "ranks, ranks_human = test_driver(test_data_generator, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAP\n",
    "class MeasurementCalculator:\n",
    "    def __init__(self, resultFromModel, threshold=1):\n",
    "        self.resultFromModel = resultFromModel\n",
    "        self.binaryResult = self.toBinaryResult(threshold)\n",
    "        \n",
    "    def toBinaryResult(self, threshold):\n",
    "        binaryResult = []\n",
    "        for eachBatch in self.resultFromModel:\n",
    "            eachBinaryResult = []\n",
    "            for eachComment in eachBatch:\n",
    "                \n",
    "                # eachComment[0] -> score\n",
    "                # eachComment[1] -> cid\n",
    "                # eachComment[2] -> label\n",
    "                currentLabel = eachComment[2]\n",
    "                if currentLabel >= threshold:\n",
    "                    eachBinaryResult.append(1)\n",
    "                else:\n",
    "                    eachBinaryResult.append(0)\n",
    "                    \n",
    "            if len(eachBinaryResult) != len(eachBatch):\n",
    "                print('binary single batch length not equal to each bathch size...')\n",
    "                return None\n",
    "            binaryResult.append(eachBinaryResult)\n",
    "        return binaryResult\n",
    "        \n",
    "    def precisionAtk(self, r, k):\n",
    "        \"\"\"Score is precision @ k\n",
    "        Relevance is binary (nonzero is relevant).\n",
    "        >>> r = [0, 0, 1]\n",
    "        >>> precisionAtk(r, 1)\n",
    "        0.0\n",
    "        >>> precisionAtk(r, 2)\n",
    "        0.0\n",
    "        >>> precisionAtk(r, 3)\n",
    "        0.33333333333333331\n",
    "        >>> precisionAtk(r, 4)\n",
    "        Traceback (most recent call last):\n",
    "            File \"<stdin>\", line 1, in ?\n",
    "        ValueError: Relevance score length < k\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "        Returns:\n",
    "            Precision @ k\n",
    "        Raises:\n",
    "            ValueError: len(r) must be >= k\n",
    "        \"\"\"\n",
    "        assert k >= 1\n",
    "        r = np.asarray(r)[:k] != 0\n",
    "    #     print('processing:')\n",
    "    #     print(r)\n",
    "    \n",
    "        if r.size != k:\n",
    "            raise ValueError('Relevance score length < k')\n",
    "        return np.mean(r)\n",
    "\n",
    "    def averagePrecision(self, r):\n",
    "        \"\"\"Score is average precision (area under PR curve)\n",
    "        Relevance is binary (nonzero is relevant).\n",
    "        >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "        >>> delta_r = 1. / sum(r)\n",
    "        >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
    "        0.7833333333333333\n",
    "        >>> average_precision(r)\n",
    "        0.78333333333333333\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "        Returns:\n",
    "            Average precision\n",
    "        \"\"\"\n",
    "        r = np.asarray(r) != 0\n",
    "        out = [self.precisionAtk(r, k + 1) for k in range(r.size) if r[k]]\n",
    "        if not out:\n",
    "            return 0.\n",
    "        return np.mean(out)\n",
    "\n",
    "#     def meanAveragePrecision(self, rs):\n",
    "    def meanAveragePrecision(self):\n",
    "        \"\"\"Score is mean average precision\n",
    "        Relevance is binary (nonzero is relevant).\n",
    "        >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "        >>> mean_average_precision(rs)\n",
    "        0.78333333333333333\n",
    "        >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
    "        >>> mean_average_precision(rs)\n",
    "        0.39166666666666666\n",
    "        Args:\n",
    "            rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "        Returns:\n",
    "            Mean average precision\n",
    "        \"\"\"\n",
    "        rs = self.binaryResult\n",
    "        return np.mean([self.averagePrecision(r) for r in rs])\n",
    "    \n",
    "    # MRR\n",
    "#     def meanReciprocalRank(rs):\n",
    "    def meanReciprocalRank(self):\n",
    "        # Eample\n",
    "        \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "        First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "        Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "        >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "        >>> mean_reciprocal_rank(rs)\n",
    "        0.61111111111111105\n",
    "        >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "        >>> mean_reciprocal_rank(rs)\n",
    "        0.5\n",
    "        >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "        >>> mean_reciprocal_rank(rs)\n",
    "        0.75\n",
    "        Args:\n",
    "            rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "        Returns:\n",
    "            Mean reciprocal rank\n",
    "        \"\"\"\n",
    "        rs = self.binaryResult\n",
    "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "    \n",
    "    # AveRec\n",
    "    def recallAtk(self, r, k):\n",
    "        assert k >= 1\n",
    "        totalOne = sum(r)\n",
    "        retrivedOne = sum(r[:k])\n",
    "        return retrivedOne / totalOne\n",
    "\n",
    "    def averageRecallEach(self, r):\n",
    "        #r = np.asarray(r) != 0\n",
    "        #out = [self.recallAtk(r, k + 1) for k in range(r.size) if r[k]]\n",
    "        out = [self.recallAtk(r, k + 1) for k in range(len(r)) if r[k]]\n",
    "        if not out:\n",
    "            return 0.\n",
    "        return np.mean(out)\n",
    "\n",
    "    def averageRecall(self):\n",
    "        rs = self.binaryResult\n",
    "        return np.mean([self.averageRecallEach(r) for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = MeasurementCalculator(ranks, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7443208571788503\n",
      "0.6422760770975056\n",
      "0.8404761904761904\n"
     ]
    }
   ],
   "source": [
    "print(mc.meanAveragePrecision())\n",
    "print(mc.averageRecall())\n",
    "print(mc.meanReciprocalRank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is shown above. The MAP is 74.43% and the MRR is 84.04%. We didn't show the averageRecall because it is not a standard matric to evaluate the ranking and doesn't have a unified definition. Thus its value isn't informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
