{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length = 100\n",
    "vector_size = 300\n",
    "train_path = 'v3.2/train/'\n",
    "train_fileName = 'SemEval2016-Task3-CQA-QL-train-part1-subtaskA.xml'\n",
    "test_path = 'v3.2/test/'\n",
    "test_fileName = 'SemEval2016-Task3-CQA-QL-test-subtaskA.xml'\n",
    "word2vec_matrix = 'GoogleNews-vectors-negative300.bin'\n",
    "cQA_train_embedding_name = 'cQA_train_embedding'\n",
    "cQA_test_embedding_name = 'cQA_test_embedding_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rawDataExtractor:\n",
    "    def __init__(self, path, fileName):\n",
    "        self.tree = ET.parse(path + fileName)\n",
    "        self.root = self.tree.getroot()\n",
    "        \n",
    "    def extractInformation_QA(self, test = False, testSize = 5):\n",
    "        '''\n",
    "        This function returns a python dictionary which has the following structure:\n",
    "        infoDic = {\n",
    "            'Q1_R1': {\n",
    "                'qTime': unixtime\n",
    "                'qSubject': string\n",
    "                'qUserID': string\n",
    "                'qUserID_INT': int\n",
    "                'qBody': string\n",
    "                'comments': {\n",
    "                    'cID': {\n",
    "                        'cTime': unixtime\n",
    "                        'cUserID': string\n",
    "                        'cUserID_INT': int\n",
    "                        'cBody': string\n",
    "                        'cLabel': string  \n",
    "                    }  \n",
    "                    ...\n",
    "                }\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "        '''\n",
    "        infoDic = {}\n",
    "        # For testing ONLY:\n",
    "        count = 0\n",
    "        for child in self.root:\n",
    "            # For testing ONLY:\n",
    "            if test:\n",
    "                count += 1\n",
    "                if count > testSize:\n",
    "                    return infoDic\n",
    "            \n",
    "            # Get the question key\n",
    "            currentQuestionKey = child.attrib.get('THREAD_SEQUENCE')\n",
    "            \n",
    "            # Get the question dictionary\n",
    "            currentQuestion = self.extractSingleInformation(child)\n",
    "            if not infoDic.get(currentQuestionKey):\n",
    "                infoDic[currentQuestionKey] = currentQuestion\n",
    "            else:\n",
    "                print('%s key has already existed. Info extraction failed...')\n",
    "                return None\n",
    "        return infoDic\n",
    "    \n",
    "    # Use this function when loading 'SemEval2016-Task3-CQA-QL-train-part1-subtaskA.xml' ONLY!\n",
    "    def extractSingleInformation(self, child):\n",
    "        singleInfoDic = {}\n",
    "        singleInfoDic['comments'] = {}\n",
    "        for index in range(len(child)):    \n",
    "            # Question\n",
    "            element = child[index]\n",
    "            if index == 0 and element.attrib.get('RELQ_ID'):\n",
    "                singleInfoDic['qTime'] = element.attrib.get('RELQ_DATE')\n",
    "#                 singleInfoDic['qID'] = element.attrib.get('RELQ_ID')\n",
    "                singleInfoDic['qUserID'] = element.attrib.get('RELQ_USERID')\n",
    "                sUserID_int = int(singleInfoDic['qUserID'].replace('U', ''))\n",
    "                singleInfoDic['qUserID_INT'] = sUserID_int\n",
    "            \n",
    "                singleInfoDic['qSubject'] = element[0].text\n",
    "                singleInfoDic['qBody'] = element[1].text   \n",
    "            else:\n",
    "                commentKey = element.attrib.get('RELC_ID') #cID\n",
    "                singleInfoDic['comments'][commentKey] = {}\n",
    "                singleInfoDic['comments'][commentKey]['cTime'] = element.attrib.get('RELC_DATE')\n",
    "                singleInfoDic['comments'][commentKey]['cUserID'] = element.attrib.get('RELC_USERID')\n",
    "                cUserID_int = int(singleInfoDic['comments'][commentKey]['cUserID'].replace('U', ''))\n",
    "                singleInfoDic['comments'][commentKey]['cUserID_INT'] = cUserID_int\n",
    "                singleInfoDic['comments'][commentKey]['cBody'] = element[0].text\n",
    "                \n",
    "                label = element.attrib.get('RELC_RELEVANCE2RELQ')\n",
    "                singleInfoDic['comments'][commentKey]['cLabel'] = label\n",
    "                \n",
    "                if label == 'Good':\n",
    "                    singleInfoDic['comments'][commentKey]['cLabel_INT'] = 2\n",
    "                elif label == 'Bad':\n",
    "                    singleInfoDic['comments'][commentKey]['cLabel_INT'] = 0\n",
    "                else:\n",
    "                    singleInfoDic['comments'][commentKey]['cLabel_INT'] = 1\n",
    "        return singleInfoDic\n",
    "    \n",
    "    # Use this function when loading 'SemEval2016-Task3-CQA-QL-train-part1.xml' ONLY!\n",
    "    def extractInformation_QQ(self):\n",
    "        '''\n",
    "        This function returns a python dictionary which has the following structure:\n",
    "        infoDic = {\n",
    "            'Q1': {\n",
    "                'qTargetSubject': string\n",
    "                'qTargetBody': string\n",
    "                'availableQs': {\n",
    "                    'qTime': unixtime\n",
    "                    'qSubject': string\n",
    "                    'qUserID': string\n",
    "                    'qUserID_INT': int\n",
    "                    'qBody': string\n",
    "                    'qLabel': string\n",
    "                    'qLabel_INT': int   \n",
    "                }\n",
    "                ...\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2Vec:\n",
    "    def __init__(self, word2vec_dir, vector_dim, sentence_length):\n",
    "        self.model = KeyedVectors.load_word2vec_format(word2vec_dir, binary=True)\n",
    "        self.vector_dim = vector_dim\n",
    "        self.sentence_length = sentence_length\n",
    "        self.pattern = re.compile(r\"[^\\w]\")\n",
    "        replace_op = lambda x: self.pattern.sub('', x)\n",
    "        self.ops = [lambda x: x, lambda x: x.lower(), lambda x: x.capitalize(), lambda x: x.upper(), \\\n",
    "                   lambda x: replace_op(x), lambda x: replace_op(x).lower(), \\\n",
    "                    lambda x: replace_op(x).capitalize(), lambda x: replace_op(x).upper()]\n",
    "        \n",
    "    def embed_sentence(self, sentence):\n",
    "        words = sentence.strip().split()\n",
    "        vectors = []\n",
    "        for w in words[:self.sentence_length]:\n",
    "            for op in self.ops:\n",
    "                new_w = op(w)\n",
    "                if new_w in self.model.vocab:\n",
    "                    vectors.append(self.model[new_w].reshape((1, -1)))\n",
    "                    break\n",
    "            else:\n",
    "                vectors.append(np.random.uniform(low=-0.25, high=0.25, size=(1, self.vector_dim)))\n",
    "        if len(vectors) < self.sentence_length:\n",
    "            vectors.append(np.zeros((self.sentence_length - len(vectors), self.vector_dim)))\n",
    "        return np.concatenate(vectors, axis=0).reshape(1, self.sentence_length, self.vector_dim)\n",
    "    \n",
    "    def build_matrix(self, raw_dict, save_dir):\n",
    "        q_vectors = []\n",
    "        a_vectors = []\n",
    "        labels = []\n",
    "        aug_data = []\n",
    "        cid_list = []\n",
    "        for thread in raw_dict.values():\n",
    "            q_vector = self.embed_sentence((thread['qSubject'] if thread['qSubject'] else '') + \\\n",
    "                                           ' ' + thread['qBody'] if thread['qBody'] else '')\n",
    "            q_id = thread['qUserID_INT']\n",
    "            for cid, comment in thread['comments'].items():\n",
    "                q_vectors.append(q_vector)\n",
    "                a_vectors.append(self.embed_sentence(comment['cBody'] if comment['cBody'] else ''))\n",
    "                labels.append(np.array([[comment['cLabel_INT'] / 2]]))\n",
    "                aug_data.append(np.array([[0.0 if q_id != comment['cUserID_INT'] else 1.0]]))\n",
    "                cid_list.append([[cid]])\n",
    "        q_vec = np.concatenate(q_vectors, axis=0)\n",
    "        a_vec = np.concatenate(a_vectors, axis=0)\n",
    "        label_vec = np.concatenate(labels, axis=0)\n",
    "        aug_vec = np.concatenate(aug_data, axis=0)\n",
    "        cid_vec = np.concatenate(cid_list, axis=0)\n",
    "        np.savez(save_dir, q_vec, a_vec, aug_vec, label_vec, cid_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2v = Text2Vec(word2vec_matrix, vector_size, sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDE = rawDataExtractor(train_path, train_fileName)\n",
    "raw_dict = rDE.extractInformation_QA(test = False, testSize = 50)\n",
    "t2v.build_matrix(raw_dict, cQA_train_embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDE = rawDataExtractor(test_path, test_fileName)\n",
    "raw_dict = rDE.extractInformation_QA(test = False, testSize = 50)\n",
    "t2v.build_matrix(raw_dict, cQA_test_embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6442745"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(t2v.model['grab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [['a'], ['b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for x in np.concatenate(a, axis=0):\n",
    "    print(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
